

# [kubebuilder开发](https://www.cnblogs.com/wuchangblog/p/17416221.html)



通过编写的api、markers规则

make generate生成go文件

make manifests生成资源清单（即kind:CustomResourceDefinition的配置）

[进阶 K8s 高级玩家必备 | Kubebuilder：让编写 CRD 变得更简单](https://mp.weixin.qq.com/s/Gzpq71nCfSBc1uJw3dR7xA)

[Kubernetes 的核心是 API 而非容器](https://mp.weixin.qq.com/s/MEhDJYg_lmjbPEdFFLdedg)

[面向 K8s 设计误区](https://mp.weixin.qq.com/s/W_UjqI0Rd4AAVcafMiaYGA)



#### [Return Options 退货选项](https://kubebuilder.io/getting-started#return-options)

The following are a few possible return options to restart the Reconcile:
以下是重新启动 Reconcile 的几个可能的返回选项：

- With the error: 出现错误：

```go
return ctrl.Result{}, err
```

- Without an error: 没有错误：

```go
return ctrl.Result{Requeue: true}, nil
```

- Therefore, to stop the Reconcile, use:
  因此，要停止 Reconcile，请使用：

```go
return ctrl.Result{}, nil
```

- Reconcile again after X time:
  X 次后再次对账：

```go
return ctrl.Result{RequeueAfter: nextRun.Sub(r.Now())}, nil
```





```go
if err := c.Watch(

​        source.Kind(mgr.GetCache(), &helmv2b1.HelmRelease{}),

​        handler.EnqueueRequestsFromMapFunc(a.objectToApplicationFunc),

​    )
```

watch监控服务事件，kind将资源加入缓存



以上的先不用看

---



# [client-go](https://www.zhihu.com/question/290497164/answer/3130603953)

[组件解析](https://andblog.cn/)

### Reflector

Reflector 用于监控（Watch）指定的 Kubernetes 资源，当监控的资源发生变化时，例如 Add 事件、Update 事件、Delete 事件，并将其资源对象存放到本地缓存 DeltaFIFO 中。

### Deltafifo

DeltaFIFO 是一个生产者-消费者的队列，生产者是 Reflector，消费者是 informer Pop 函数，FIFO 是一个先进先出的队列，而 Delta 是一个资源对象存储，它可以保存资源对象的操作类型，例如 Add 操作类型、Update 操作类型、Delete 操作类型、Sync 操作类型等。

### Indexer

Indexer 是 client-go 用来存储资源对象并自带索引功能的本地存储，informer 从 DeltaFIFO 中将消费出来的资源对象存储至 Indexer。Indexer 与 Etcd 集群中的数据保持完全一致。这样我们就可以很方便地从本地存储中读取相应的资源对象数据，而无须每次从远程 APIServer 中读取，以减轻服务器的压力。

### Informer

Informer 将上述三个组件协同运行起来，保证整个流程串联起来，是 client-go 中的大脑。

### Workqueue 

是一个先进先出的队列，informer 将事件获取到并不及时处理，先将事件 push 到 workqueue 中，然后再从 workqueue 消费处理。大大提高运行效率



`annotations` 是附加到 Kubernetes 资源上的元数据。与标签（labels）不同，标签用于标识和选择资源，而注解（annotations）用于存储任意的非标识性的信息，通常用于存储可能对程序或操作有用的辅助信息，但这些信息对于 Kubernetes 系统本身的操作并不重要。通过注解来判断资源的所有权，并据此进行清理。这是一种常见的模式，用于在 Kubernetes 中管理由应用程序或控制器动态创建的资源。



# Scheme 存储了 GVK 和 Go type 的映射关系

目前k8s系统中的所有资源类型都已注册到Scheme资源注册表中，其是一个内存型的资源注册表，拥有如下特点：

● 支持注册多种资源类型，包括内部版本和外部版本。（调用AddToScheme进行GVK（就是各种资源）注册）

● 支持多种版本转换机制。

● 支持不同资源的序列化/反序列化机制。（kubectl将输入的yaml配置转换成k8s对象）

[详细解析](https://zhuanlan.zhihu.com/p/384590193)



在 Kubernetes API 设计中，顶级资源对象（Top-level Resource Object）是指可以直接作为 Kubernetes API 端点的资源对象。这意味着它们可以独立地通过 Kubernetes API 被创建、更新、删除和查询。顶级资源对象通常具有以下特点：

1. **独立的 API 路径**：顶级资源对象在 Kubernetes API 中有自己独立的路径。例如，`/api/v1/pods` 中的 `Pod` 资源是一个顶级资源对象。

2. **可独立操作**：它们可以被 Kubernetes API 客户端直接操作，无需依赖于其他对象。

3. **完整的生命周期**：顶级资源对象拥有自己的生命周期，包括创建、存在和删除的全过程。

4. **清单文件中的根元素**：在 Kubernetes 的配置清单（manifest）文件中，顶级资源对象是 JSON 或 YAML 文件的根元素。

5. **自定义资源定义（CRD）**：用户定义的顶级资源对象通常是通过 Kubernetes 的 CRD 机制创建的。它们允许用户扩展 Kubernetes API，创建自定义的对象类型。

6. **API 组（Group）、版本（Version）和资源（Resource）**：顶级资源对象通过 `GroupVersionResource`（GVR）来唯一标识。对于内置的 Kubernetes 资源，如 `Pod`，GVR 可能看起来像 `core/v1/Pod`，而对于 CRD，它可能包括自定义的 API 组，如 `mycompany.com/v1/MyCustomResource`。

在提供的代码示例中，`Application` 结构体通过 `+kubebuilder:object:root=true` 标记被指定为顶级资源对象。这意味着 `Application` 将作为一个独立的资源对象被 Kubernetes API 服务器识别，并且可以通过 Kubernetes API 进行操作。此外，它还可以拥有自己的 RESTful 端点，允许用户通过标准的 HTTP 请求来获取、创建、更新或删除 `Application` 实例。







Manager 管理控制器，控制器提供协调功能，用于同步资源，直到在集群中达到所需状态。





# [蓝绿发布、A/B测试、金丝雀发布](https://fluxcd.io/flagger/usage/deployment-strategies/)

### **A/B 测试 vs Canary 发布 vs 蓝绿发布**

| **特性**       | **A/B 测试**                             | **Canary 发布**                          | **蓝绿发布**                               |
| -------------- | ---------------------------------------- | ---------------------------------------- | ------------------------------------------ |
| **主要目的**   | 优化产品功能和用户体验                   | 安全、渐进式地发布新版本                 | 无缝切换和快速部署新版本                   |
| **部署方式**   | 同时运行多个版本，针对不同用户群体       | 渐进式地将新版本推向所有用户             | 维持两个独立的生产环境，切换流量           |
| **用户分配**   | 随机、基于实验设计                       | 按比例逐步增加新版本的用户覆盖率         | 一次性切换所有用户到新环境或回滚           |
| **监控重点**   | 用户行为、特定指标（如转化率、点击率）   | 系统性能、错误率、稳定性                 | 整体系统运行状态、新版本的全面表现         |
| **资源需求**   | 较低，通常在单一环境中进行               | 略高，需支持多版本并行运行               | 高，需要维护双倍的生产环境                 |
| **复杂性**     | 需要设计实验、数据分析和结果解读         | 需要流量路由、监控和逐步部署机制         | 需要管理和维护两个独立的环境               |
| **适用场景**   | 产品功能和用户体验的持续优化             | 需要频繁发布且希望分阶段验证新版本稳定性 | 需要快速、无缝地切换生产环境，减少停机时间 |
| **风险控制**   | 限制在特定指标上的优化或变化             | 分阶段控制风险，出现问题影响范围小       | 一次性风险暴露，但回滚迅速                 |
| **回滚难易度** | 通过停止实验或调整用户分配比例           | 逐步减少新版本流量，恢复旧版本           | 只需切换路由回到旧环境即可                 |
| **用户体验**   | 不同用户可能体验不同版本，需明确测试目的 | 大多数用户仍使用旧版本，少部分体验新版本 | 所有用户无感知切换，保持一致的体验         |

### **选择合适的策略**

选择 A/B 测试、Canary 发布或蓝绿发布，取决于具体的业务需求、资源情况和目标。以下是一些决策参考：

1. **优化目标：**
   - **A/B 测试** 适用于需要深入了解用户行为、优化产品功能和用户体验的场景。
   - **Canary 发布** 和 **蓝绿发布** 更多关注于新版本的稳定、安全发布，减少部署风险。

2. **资源和基础设施：**
   - **A/B 测试** 通常不需要额外的环境支持，可以在现有环境中进行。
   - **蓝绿发布** 需要维护两个独立的生产环境，资源消耗较大。
   - **Canary 发布** 需要支持多版本共存和流量管理，资源需求介于两者之间。

3. **发布频率和迭代速度：**
   - **A/B 测试** 和 **Canary 发布** 都适合频繁发布和快速迭代的项目。
   - **蓝绿发布** 更适合发布频率较低，但对切换速度和可靠性要求高的场景。

4. **风险管理：**
   - **A/B 测试** 能通过小范围实验验证假设，降低因改动带来的业务风险。
   - **Canary 发布** 能逐步部署新版本，控制风险逐步暴露。
   - **蓝绿发布** 虽能快速切换，但一次性暴露所有用户到新版本，风险控制依赖于切换的精准性。

5. **用户体验需求：**
   - **A/B 测试** 可能导致部分用户体验到不同的版本，这在某些产品优化中是需要的。
   - **Canary 发布** 大部分用户体验旧版本，少部分体验新版本。
   - **蓝绿发布** 对用户透明，无感知切换，保持一致的体验。

### **综合应用**

在实际应用中，**A/B 测试**、**Canary 发布**和**蓝绿发布**并非互斥关系，而是可以根据不同需求和阶段相互结合，共同优化软件发布和产品功能。例如：

- **产品优化阶段：** 采用 A/B 测试，验证不同功能或设计的效果。
- **版本发布阶段：** 利用 Canary 发布或蓝绿发布，确保新版本的稳定性和可靠性。
- **持续迭代过程中：** 结合 A/B 测试的优化结果，持续改进产品，同时通过 Canary 或蓝绿发布确保每次迭代的平滑过渡。

### **总结**

- **A/B 测试** 主要用于产品功能和用户体验的优化，通过对比实验获取数据驱动的决策支持。
- **Canary 发布** 是一种渐进式的部署策略，通过逐步扩大新版本的用户覆盖范围，降低发布风险。
- **蓝绿发布** 通过维护双环境，实现新旧版本的快速切换，适合需要无缝部署和快速回滚的场景。

根据具体的业务需求、资源状况和优化目标，合理选择和组合这些策略，有助于实现高效、安全和用户友好的软件交付流程。







# Prometheus

Prometheus 在启动时使用集群内部的 `ServiceAccount` 自动获取 Kubernetes API 的访问权限。

集群管理员需要通过 RBAC（基于角色的访问控制）来授予 Prometheus 读取资源的权限。

1. **ServiceAccount**: 创建一个名为 `prometheus` 的 ServiceAccount，用于 Prometheus Pod。
   **ServiceAccount**： 创建一个名为 `prometheus` 的 ServiceAccount，用于 Prometheus Pod。
2. **ClusterRole**: 定义一个 ClusterRole，授予 Prometheus 读取 Pods、Services、Endpoints 等资源的权限。
3. **ClusterRoleBinding**: 将 ClusterRole 绑定到 ServiceAccount，确保 Prometheus 有权访问所需的 Kubernetes 资源。
   **ClusterRoleBinding**： 将 ClusterRole 绑定到 ServiceAccount，确保 Prometheus 有权访问所需的 Kubernetes 资源。

Prometheus 可以通过 Kubernetes 的 API 自动发现 Pod 的 IP 地址（即 `__meta_kubernetes_pod_ip`）。

**Pod 的端口和路径**：通过 Pod 注解（annotations），Prometheus 能够知道需要抓取的指标路径和端口。

**Prometheus 结合 `relabel_configs` 重新生成目标地址**：通过 `__meta_kubernetes_pod_annotation_prometheus_io_port` 和 `__meta_kubernetes_pod_annotation_prometheus_io_path` 注解，Prometheus 组合出完整的 URL，比如 `http://<pod-ip>:<port>/<metrics-path>`。



### 数据格式

Prometheus通过轮询的方式从Exporter获取监控数据，当然数据需要遵循一定的格式，不然Prometheus也是无法识别的，这个格式就是**Metrics**格式.

主要分为三个部分 各个部分需符合相关的正则表达式

- metric name：指标的名称，主要反映被监控样本的含义`a-zA-Z_:*`_
- label name: 标签 反映了当前样本的特征维度`[a-zA-Z0-9_]*`
- label value: 各个标签的值，不限制格式

### 数据类型

Prometheus定义了4种不同的指标类型(metric type)：Counter（计数器）、Gauge（仪表盘）、Histogram（直方图）、Summary（摘要）

- Counter

只增不减的计数器，比如可以在应用程序中记录某些事件发生的次数；常见的监控指标，如http_requests_total；

```ini
ini 代码解读复制代码# HELP jvm_gc_memory_allocated_bytes_total Incremented for an increase in the size of the young generation memory pool after one GC to before the next
# TYPE jvm_gc_memory_allocated_bytes_total counter
jvm_gc_memory_allocated_bytes_total{application="springboot-actuator-prometheus-test",} 6.3123664E9
```

- Gauge

侧重于反应系统的当前状态，可增可减；常见指标如：node_memory_MemFree（主机当前空闲的内容大小）、node_memory_MemAvailable（可用内存大小）；

```ini
ini 代码解读复制代码# HELP jvm_threads_live_threads The current number of live threads including both daemon and non-daemon threads
# TYPE jvm_threads_live_threads gauge
jvm_threads_live_threads{application="springboot-actuator-prometheus-test",} 20.0
```

- Histogram和Summary

主用用于统计和分析样本的分布情况

## 自己的时序存储TSDB![img](https://www.yuandangsheng.top/%22wp-content/uploads%22/2023/09/image321.png)

prometheus监控数据默认每15s采集一次，默认数据保留15天（15天之前的数据会滚动删除）

如下图所示，Head块位于内存，而灰色Block块是磁盘上的持久块。为了防止数据丢失，会先构建持久写的预写日志(Write-Ahead-Log, WAL)。传入的样本(紫色框)，首先进入Head块并在内存中停留一段时间，然后刷新到磁盘并进行内存映射(M-map)。当这些内存映射块或内存中的块老化到一定程度时，它们将作为持久块刷新到磁盘Block。当多个块变老时，它们将被合并，并在超过保留期后最终被删除。

![img](https://ctyun-developers-0510.gdoss.xstore.ctyun.cn/prod/0203768e606546558841f8170548286e.png)

存储结构示意图

[具体](https://www.ctyun.cn/developer/article/465616168554565)

### 长期存储Thanos

Thanos 由 Improbable 开源，是社区最先出现的 Prometheus 长期存储方案，采用者包括 Adobe、字节、eBay、腾讯等。

Thanos 可以使用 MinIO 作为其对象存储后端

Thanos 在架构上较为创新，具有诸多较为独特的功能：

- 能够提供 Prometheus 实例的全局查询视图，可以跨越多个 Prometheus 实例对数据进行查询和聚合；
- 可以把数据通过 Sidecar 上传至对象存储以便长时间保存；
- 提供压缩与降采样功能，通过压缩可以减小对象存储上保存的 Block 的大小，通过降采样可以加快长时间范围数据的查询与聚合速度。

Thanos 有两种模式，Sidecar 模式和 Receive 模式。

**Thanos Sidecar 模式**

![img](https://ask.qcloudimg.com/http-save/4932777/4c27704e6cf361f180b7e61402731dc6.png)

ThanosSidecar 模式是 Thanos 最早支持的模式，其原理是：

- 每个 Prometheus Pod 中都有一个 Sidecar，这个 Sidecar 通过 Store API 与外界交互；
- Thanos Query 通过 Store API 与 Thanos Sidecar 交互，经由 Thanos Sidecar 查询到各 Prometheus 实例上的数据后进行聚合，去重后提供给用户一个跨多个 Prometheus 实例的全局视图；
- Thanos Sidecar 中的 Shipper 会把本地 Prometheus 实例落盘的 Block 上传到对象存储，之后由 Thanos Compact 对上传到对象存储的 Block 进行压缩、降采样和过期删除；
- 存储在对象存储里的 Block 可由 Store Gateway 通过 Store API 向 Thanos Query 提供查询服务，Store Gateway 会缓存对象存储里 Block 的 index 以加快查询速度；
- 此外，Thanos Query 前面还有 Thanos Query Frontend 用于缓存查询结果以加快查询速度；
- Thanos Ruler 用于通过查询 Thanos Query 计算 Recording 或 Alerting Rules。

Sidecar 模式下，在每一个 Prometheus 实例旁添加一个 Thanos Sidecar 组件，以此来实现对 Prometheus 的管理。主要有两个功能：

  - 接受 Query 组件的查询请求。在 Thanos 查询短期数据时，请求会转到 Sidecar。
  - 上传 Prometheus 的短期指标数据。默认每两个小时，创建一个块，上传到对象存储。

  优势:

  - 集成容易，不需要修改原有配置

  缺点:

  - 近期数据需要 Query 与 Sidecar 之间网络请求完成，会增加额外耗时
  - 需要 Store Gateway 能访问每个 Prometheus 实例

**Thanos Receive 模式**

![img](https://ask.qcloudimg.com/http-save/4932777/f3f9b176cbbdd43f895e0203592764e0.png)

Thanos Receive 模式是 Thanos 响应社区用户 Remote Write 的需求新增的模式，其原理是：

- Prometheus 或 Prometheus Agent 通过 Remote Write 将监控数据发送到 Thanos Receive Router；
- Thanos Receive Router 根据租户信息将数据发送给响应的 Thanos Receive Ingestor，其中 Router 是无状态的，Ingestor 是有状态的；
- Thanos Receive Ingestor 相当于在一个没有数据抓取能力和告警能力的 Prometheus 之上增加了 Store API 的支持用于和 Thanos Query/Thanos Ruler 交互，增加了 Shipper 组件将落盘 Block 上传对象存储；
- Thanos Query 可以统一查询 Thanos Ingestor、Thanos Store Gateway；
- 其他组件作用和 Thanos Sidecar 模式类似。

Receive 模式下，需要在每一个 Prometheus 实例中配置 remote write 将数据上传给 Thanos。此时，由于实时数据全部都存储到了 Thanos Receiver，因此不需要 Sidecar 组件即可完成查询。

优势：

- 数据集中
- Prometheus 无状态
- 只需要暴露 Receiver 给 Prometheus 访问

缺点:

- Receiver 承受大量 Prometheus 的 remote write 写入


![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/9b1a5c746e6040ed299d9be1df82ee0b.png)

# Kurator 馆长

## Overview 概述

Kurator是一个开源的分布式云原生平台，帮助用户构建自己的分布式云原生基础设施，助力企业数字化转型。
Kurator 站在许多流行的云原生软件堆栈的肩膀上，包括 [Kubernetes](https://github.com/kubernetes/kubernetes)、[Istio](https://github.com/istio/istio)、[Prometheus](https://github.com/prometheus/prometheus)、[FluxCD](https://github.com/fluxcd/flux2)、[KubeEdge](https://github.com/kubeedge/kubeedge)、[Volcano](https://github.com/volcano-sh/volcano)、[Karmada](https://github.com/karmada-io/karmada)、[Kyverno](https://github.com/kyverno/kyverno) 等。

问到这些社区帮我查

---

# [About Admission Controllers](https://kyverno.io/docs/introduction/admission-controllers/)

# Docker

docker 底层依赖于namespace cgroup 根文件系统这三种内核提供的机制，其中namespace主要用于进程间资源的隔离，而cgroup则是用于资源访问的限制，根文件系统则是为docker提供了一个虚拟的根文件系统，挂载在主机的文件目录下。根文件系统由busybox制作并使用系统调用chroot对docker进程组中的根文件系统进行切换。
对于docker的网络有四种模式
host（与主机共用网络资源，如网卡ip等）不需要进行NAT性能更好，但是docker host上已经使用的端口就不能再用了网络的隔离性不好。通过进程号区分网络包
Container（而是和一个指定的容器共享IP、端口范围）
Bridge（默认设置）：此模式会为每一个容器分配、设置IP等，并将容器连接到一个docker0虚拟网桥，通过docker0网桥以及Iptables nat表配置与宿主机通信。在bridge模式下，连在同一网桥上的容器可以相互通信
None（不使用网络功能）这种网络模式下容器只有lo回环网络，封闭的网络能很好的保证容器的安全性



虚拟化技术主要分为三类，其中前两类都属于硬件虚拟化：
主机虚拟化，一台物理机可以被划分为若干个小的机器，每个机器的硬件互不共享，各自安装操作系统
硬件虚拟化，同一个物理机上隔离多个操作系统实例 例如kvm+qemu
操作系统虚拟化，由操作系统创建虚拟的系统环境，使应用感知不到其他应用的存在，比如说docker
对于虚拟化分为：io虚拟化 cpu 虚拟化和内存虚拟化



在虚拟机运行期间，QEMU会通过KVM模块提供的系统调用进人内核，由KVM模块负责将虚拟机置于处理器的特殊模式运行。遇到虚拟机进行输入输出操作，KVM模块会从上次的系统调用出口处返回QEMU，由QEMU来负责解析和模拟这些设备。

## k8s上部署一个项目

## 1. Namespace（命名空间）

**用途：**  
用于将集群内的资源进行逻辑分组，便于资源的隔离和管理。例如，可以为不同的开发、测试和生产环境创建独立的命名空间。

**关键点：**
- 隔离资源，防止不同项目或环境之间的资源冲突。
- 可以配合网络策略和资源配额进行更细粒度的管理。

## 2. Pod（容器集）

**用途：**  
Kubernetes 中最小的可部署单元，一个 Pod 通常包含一个或多个紧密相关的容器。

**关键点：**
- 容器共享存储、网络和命名空间。
- 适用于紧密协作的容器，例如一个主应用容器和一个辅助的 sidecar 容器。

## 3. ReplicaSet（副本集）

**用途：**  
确保指定数量的 Pod 实例始终运行。通常由 Deployment 管理。

**关键点：**
- 自动替换不可用的 Pod，保证高可用性。
- 主要通过 Deployment 进行间接管理。

## 4. Deployment（部署）

**用途：**  
用于声明性地管理应用的部署和更新。它控制 ReplicaSet 和 Pod 的生命周期。

**关键点：**
- 支持滚动更新和回滚，确保应用平滑升级。
- 定义了应用的期望状态，包括镜像版本、环境变量等。

## 5. Service（服务）

**用途：**  
定义了一组 Pod 的访问策略，提供稳定的网络端点。

**关键点：**
- 支持多种类型，如 ClusterIP（集群内部访问）、NodePort（外部访问）、LoadBalancer（通过云提供商分配负载均衡器）等。
- 通过标签选择器将流量路由到匹配的 Pod。

## 6. ConfigMap（配置映射）

**用途：**  
存储配置数据，使配置与容器镜像分离，便于管理和修改配置。

**关键点：**
- 可以通过环境变量或挂载为文件的方式在 Pod 中使用。
- 支持多种数据格式，如键值对、JSON 等。

## 7. Secret（密钥）

**用途：**  
存储敏感信息，如密码、OAuth 令牌和 SSH 密钥，确保数据的安全性。

**关键点：**
- 数据以 base64 编码存储。
- 可以通过环境变量或挂载为文件的方式在 Pod 中使用。
- 支持加密存储，增强安全性。

## 8. Ingress（入口控制）

**用途：**  
管理外部 HTTP 和 HTTPS 流量进入集群的规则和路由。

**关键点：**
- 支持基于域名和路径的路由。
- 可以与 Ingress Controller 结合使用，实现负载均衡、SSL 终结等功能。
- 支持 TLS 证书管理，确保安全通信。

## 9. PersistentVolume（持久卷）和 PersistentVolumeClaim（持久卷声明）

**用途：**  
提供持久化存储，保证 Pod 重启或迁移后数据不丢失。

**关键点：**
- PersistentVolume 表示集群中的实际存储资源，如 NFS、iSCSI、云存储等。
- PersistentVolumeClaim 是对存储的请求，定义了存储的大小和访问模式。
- 支持动态供应，通过 StorageClass 自动创建 PersistentVolume。

## 10. StatefulSet（有状态集）

**用途：**  
管理有状态应用，确保 Pod 的有序部署和唯一标识。

**关键点：**
- 适用于需要稳定网络标识和持久存储的应用，如数据库、分布式缓存等。
- 提供有序的 Pod 创建、更新和删除。
- 每个 Pod 有唯一的编号和稳定的存储卷。

## 11. DaemonSet（守护进程集）

**用途：**  
确保集群中的每个节点上运行一个 Pod 实例。

**关键点：**
- 常用于部署节点级别的服务，如日志收集、监控代理等。
- 支持在新加入的节点上自动调度 Pod。

## 12. Job 和 CronJob（任务和定时任务）

**用途：**  
管理一次性或周期性的批处理任务。

**关键点：**
- Job 用于运行一次性任务，确保任务成功完成。
- CronJob 用于定期执行任务，类似于 Unix 的 cron。
- 支持重试策略和任务历史记录管理。

## 13. Role 和 RoleBinding / ClusterRole 和 ClusterRoleBinding（角色和绑定）

**用途：**  
实现基于角色的访问控制（RBAC），定义用户或服务账户对资源的访问权限。

**关键点：**
- Role 定义命名空间级别的权限，ClusterRole 定义集群级别的权限。
- RoleBinding 将 Role 绑定到用户、组或服务账户，类似地 ClusterRoleBinding 绑定集群角色。
- 确保资源的安全访问，防止未授权操作。

## 14. NetworkPolicy（网络策略）

**用途：**  
定义 Pod 之间和 Pod 与外部之间的网络访问规则，增强网络安全。

**关键点：**
- 基于标签选择器指定哪些 Pod 可以进行通信。
- 支持入站和出站流量的控制。
- 需要网络插件（如 Calico、Cilium）支持才能生效。

## 15. HorizontalPodAutoscaler（水平 Pod 自动伸缩）

**用途：**  
根据 CPU 使用率或自定义指标自动调整 Pod 的副本数量，确保应用的弹性。

**关键点：**
- 需要指定目标指标，如 CPU 使用率、内存使用率或自定义指标。
- 支持自动扩展和缩减，优化资源利用率。
- 可以与 Cluster Autoscaler 配合，自动调整集群节点数。

## 16. ServiceAccount（服务账户）

**用途：**  
提供 Pod 中运行的应用与 Kubernetes API 的安全交互身份。

**关键点：**
- 每个 ServiceAccount 有唯一的令牌，供应用访问 Kubernetes API 使用。
- 可结合 RBAC 进一步细化权限。
- 默认情况下，每个命名空间有一个默认的 ServiceAccount，建议为不同应用创建独立的 ServiceAccount。

## 17. ResourceQuota（资源配额）和 LimitRange（资源限制范围）

**用途：**  
管理命名空间内资源的使用，防止某个应用占用过多资源。

**关键点：**
- ResourceQuota 可限制命名空间内的总资源使用，如 CPU、内存、Pod 数量等。
- LimitRange 可为 Pod 或容器设置默认的资源请求和限制，确保公平使用。

## 18. CustomResourceDefinition（自定义资源定义）

**用途：**  
扩展 Kubernetes API，定义自定义的资源类型，以满足特定需求。

**关键点：**
- 通过 CRD 可以创建自定义的控制器，管理自定义资源的生命周期。
- 常用于 Operator 模式，实现特定应用的自动化管理。

## 19. Configurations and Best Practices（配置与最佳实践）

**配置文件：**
- **YAML/JSON 文件：** 使用声明式配置文件定义上述资源，便于版本控制和审计。
- **Helm Charts:** 使用 Helm 包管理工具，简化复杂应用的部署和管理。
- **Kustomize:** 利用 Kubernetes 原生的配置管理工具，支持配置的定制和复用。

**最佳实践：**
- **分离配置与代码：** 使用 ConfigMap 和 Secret 管理配置，避免将配置硬编码到镜像中。
- **版本控制：** 将所有 Kubernetes 配置文件纳入版本控制系统，确保变更的可追溯性。
- **声明式管理：** 采用声明式的资源管理方式，利用 GitOps 等工具实现持续交付。
- **安全性：** 最小权限原则，合理分配权限，保护敏感数据。
- **监控与日志：** 部署监控和日志收集组件，如 Prometheus、Grafana、ELK 等，实时监控应用状态和集群健康。
- **备份与恢复：** 定期备份关键数据和配置，制定灾备策略，确保数据安全和快速恢复。

## 总结

部署一个项目到 Kubernetes 集群，需要综合运用多种原生资源，以满足应用的运行需求、安全性、弹性和可维护性。通过合理的资源配置和管理，可以充分发挥 Kubernetes 的优势，实现高效、可靠的应用交付。
